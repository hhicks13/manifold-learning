# manifold-learning
Lie Groups + AI + Image Processing

# compressed sensing mentioned here #
https://www.nature.com/articles/s41586-019-1319-8
# symmetry group factorization for network structure (anatomy of worm neural cortex) #
https://www.nature.com/articles/s41467-019-12675-8 #
# lie operators for compressive sensing #
http://people.csail.mit.edu/chinmay/files/papers/icassp_cslie.pdf
# Universal encoding strategies! #
> pros: huge citation count + very much an optimization/IE approach
https://arxiv.org/pdf/math/0410542.pdf
> The sparse encoder is not unlike a cost matrix
> the signal reconstruction process
is similar to solving an assignment problem, if not identical.
> Unlike Deep Learning, there is a mathematically provable
guarantee that the true signal will be recovered. Good for basic science.
> challenge: finding the sparse encoder is a domain-specific problem, but this is essentially a convolution
 filter.
>Would be interesting to look into the possibility of a hybrid strategy, like learning the sparse encoder in one phase of training and then passing the rest of to a compressed sensing phase to ensure that the true signal is being recovered and not an artifact as is the case in most NNs. 

